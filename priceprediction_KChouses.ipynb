{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model to predict king county house sale prices\n",
    "\n",
    "To build a linear regression model to predict the house sale prices and evaluate models according to MAE (median absolute error) on houses with sale prices between the 5th and 95th percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt    \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('raw_data/EXTR_RPSale.csv')\n",
    "resbldg_df = pd.read_csv('raw_data/EXTR_ResBldg.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()\n",
    "resbldg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()\n",
    "resbldg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.duplicated().sum() #0 duplicated rows\n",
    "resbldg_df.duplicated().sum()    #0 duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.isna().sum()    #no NAs\n",
    "resbldg_df.isna().sum()     #has NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df1 = sales_df.loc[:, (sales_df != 0).any(axis=0)]   #No rows with all zeros\n",
    "print(sales_df.shape)\n",
    "print(sales_df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resbldg_df1 = resbldg_df.loc[:, (resbldg_df != 0).any(axis=0)]   #No rows with all zeros\n",
    "print(resbldg_df.shape)\n",
    "print(resbldg_df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resbldg_df.columns    #space in column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resbldg_df2 = resbldg_df.rename(columns={'Major ': 'Major', 'SqFtDeck  ': 'SqFtDeck'})   #renaming column header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing initial features\n",
    "sales_df2 = sales_df1[['Major', 'Minor', 'SalePrice']]     \n",
    "resbldg_df3 = resbldg_df2[['Major', 'Minor', 'SqFtTotLiving', 'Bedrooms', 'SqFtGarageAttached',   \n",
    "                   'Condition', 'SqFtDeck','BathFullCount', 'ZipCode','HeatSystem', 'YrBuilt']] \n",
    "\n",
    "resbldg_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df2['Major'] = pd.to_numeric(sales_df2['Major'], errors='coerce')    #objects into float\n",
    "sales_df2['Minor'] = pd.to_numeric(sales_df2['Minor'], errors='coerce')\n",
    "resbldg_df3['Major'] = pd.to_numeric(resbldg_df3['Major'], errors='coerce')\n",
    "\n",
    "sales_data = pd.merge(sales_df2, resbldg_df3, on=['Major', 'Minor'])       #merge datasets\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram to see the sale price distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For initial visualization, droppping the top and lowest 10% of sale prices \n",
    "lowest_10percent = np.percentile(sales_data['SalePrice'], 10)\n",
    "highest_90percent = np.percentile(sales_data['SalePrice'], 90)\n",
    "\n",
    "sales_data1 = sales_data[sales_data['SalePrice'] > lowest_10percent]\n",
    "sales_data2 = sales_data1[sales_data1['SalePrice'] < highest_90percent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sales_data2['SalePrice'], bins=30000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram above shows that sale prices are not normally distributed. Therefore, we log transformed and regenerated histogram on all SalePrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram shows log transformed prices are normally distributed.\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(np.log(sales_data[sales_data['SalePrice']> 0]['SalePrice']), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the null values\n",
    "nulls = pd.DataFrame(sales_data.isnull().sum().sort_values(ascending=False))    \n",
    "nulls.columns = ['Null Count']\n",
    "nulls.index.name = 'Feature'\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove nulls in ZipCode\n",
    "sales_data = sales_data.dropna(subset = ['ZipCode'])                     \n",
    "nulls1 = pd.DataFrame(sales_data1.isnull().sum().sort_values(ascending=False))\n",
    "print(nulls1)\n",
    "\n",
    "sales_data1.shape                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the positive values for sale price\n",
    "sales_data = sales_data[sales_data['SalePrice'] > 0]\n",
    "sales_data['SalePrice'].min()\n",
    "sales_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding LogSalePrice values as a new column to build the model on log sale prices as our target   \n",
    "# instead of raw sale prices.\n",
    "sales_data['LogSalePrice']=np.log(sales_data['SalePrice'])\n",
    "sales_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log of SalePrice is normally distributed so we kept 95% of our target values by limiting to the target values larger than mean minus two standard deviation and smaller than mean plus two standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the target values above mean minus two standard deviation and below mean plus two standard deviation\n",
    "print(sales_data['LogSalePrice'].mean())\n",
    "print(sales_data['LogSalePrice'].std())\n",
    "\n",
    "mean_minus_twostdv = sales_data['LogSalePrice'].mean() - sales_data['LogSalePrice'].std()*2\n",
    "mean_plus_twostdv = sales_data['LogSalePrice'].mean() + sales_data['LogSalePrice'].std()*2\n",
    "print(mean_minus_twostdv)\n",
    "print(mean_plus_twostdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = sales_data[(sales_data['LogSalePrice'] < mean_plus_twostdv) & \n",
    "                         (mean_minus_twostdv < sales_data['LogSalePrice'])]\n",
    "sales_data.head()\n",
    "sales_data['LogSalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only the first 5 digits of ZipCode.\n",
    "def is_integer(x):\n",
    "   try:\n",
    "       _ = int(x)\n",
    "   except ValueError:\n",
    "       return False\n",
    "   return True\n",
    "\n",
    "stringed_zips = sales_data.loc[sales_data['ZipCode'].apply(is_integer) == False, 'ZipCode']\n",
    "stringed_zips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipcode_short(x):\n",
    "    return str(x)[:5]\n",
    "\n",
    "sales_data['New_zip'] = sales_data['ZipCode'].map(zipcode_short)\n",
    "sales_data.head().T\n",
    "sales_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \"WA\", space, and \"A\",\"B\" as ZipCodes\n",
    "sales_data.drop(sales_data[ sales_data['New_zip'] == \"WA\" ].index , inplace=True)\n",
    "sales_data.drop(sales_data[ sales_data['New_zip'] == \" \" ].index , inplace=True)\n",
    "sales_data.drop(sales_data[ sales_data['New_zip'] == \"B\" ].index , inplace=True)\n",
    "sales_data.drop(sales_data[ sales_data['New_zip'] == \"A\" ].index , inplace=True)\n",
    "\n",
    "stringed_zips = sales_data.loc[sales_data['New_zip'].apply(is_integer) == False, 'New_zip']\n",
    "stringed_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial correlation top 5.\n",
    "numeric_feature = sales_data.select_dtypes(include=[np.number])\n",
    "corr = numeric_feature.corr()\n",
    "\n",
    "print(abs(corr['LogSalePrice']).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate Major and Minor into PIN\n",
    "sales_data['Major'] = sales_data.Major.astype(int)\n",
    "sales_data['Minor'] = sales_data.Minor.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['Pin'] = sales_data.Major.astype(str) + sales_data.Minor.astype(str)\n",
    "sales_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicated rows\n",
    "sales_data = sales_data.drop_duplicates()\n",
    "sales_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the top correlated features\n",
    "sales_data.columns\n",
    "sales_data = sales_data[['LogSalePrice', 'SqFtTotLiving', 'Bedrooms', 'SqFtGarageAttached', 'SqFtDeck', \n",
    "                          'BathFullCount', 'YrBuilt', 'New_zip', 'Pin']].copy()\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of features\n",
    "def correlation_heatmap(df1):\n",
    "   _, ax = plt.subplots(figsize = (15, 10))\n",
    "   colormap= sns.diverging_palette(220, 10, as_cmap = True)\n",
    "   sns.heatmap(df1.corr(), annot=True, cmap = colormap)\n",
    "\n",
    "correlation_heatmap(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the distribution of house sales based on ZipCode\n",
    "plt.xlabel('houses sold')\n",
    "plt.ylabel('counts')\n",
    "plt.hist(sales_data['New_zip'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_counts = sales_data['New_zip'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['Zip_count'] = sales_data['New_zip'].apply(lambda z: zipcode_counts[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the ZipCodes with over 15000 house sales\n",
    "sales_data_over_15k = sales_data[sales_data['Zip_count'] > 15000]\n",
    "sales_data_over_15k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zip_by_price = sales_data_over_15k.groupby('New_zip')['LogSalePrice'].mean().sort_values()\n",
    "Zip_by_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcodes = list(Zip_by_price.index)\n",
    "for zc in zcodes:\n",
    "    sales_data_over_15k[zc] = (sales_data_over_15k['New_zip'] == zc).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_over_15k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial correlation of zipcodes with logsalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature = sales_data_over_15k.select_dtypes(include=[np.number])\n",
    "corr = numeric_feature.corr()\n",
    "\n",
    "print(abs(corr['LogSalePrice']).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a multiple linear regression with top 7 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = sales_data_over_15k['LogSalePrice']\n",
    "important_feat = [ele for ele in sales_data_over_15k.columns if ele in {\n",
    "    'SqFtTotLiving', 'BathFullCount', 'Bedrooms', 'SqFtGarageAttached','SqFtDeck','YrBuilt','98006'}] \n",
    "X = sales_data_over_15k[important_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 1000, test_size=.3)\n",
    "lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(X_train, y_train)\n",
    "print(\"R^2 is:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print(\"RSSE is:\", (mean_squared_error(y_test, prediction)**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values = y_test\n",
    "plt.scatter(prediction, actual_values, alpha=.2, color='b') \n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Actual Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a function that performs a multiple linear regression separately for each of the top 7 features and evaluates based on R^2 and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist = ['SqFtTotLiving', 'BathFullCount', 'Bedrooms', 'SqFtGarageAttached','SqFtDeck','YrBuilt','98006'] \n",
    "def eachfeature(featurelist):\n",
    "    X = None\n",
    "    for feature in featurelist:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(np.array(\n",
    "            sales_data_over_15k[feature]).reshape(-1,1), Y, random_state = 1000, test_size=.3)\n",
    "        lr = linear_model.LinearRegression()\n",
    "        model = lr.fit(X_train, y_train)\n",
    "        print(f\"R^2 for {feature} is:{model.score(X_test, y_test)}\") \n",
    "        print(f\"mean_absolute_error for {feature} is: {metrics.mean_absolute_error(y_test, lr.predict(X_test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eachfeature(featurelist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
